{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, glob\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import schedule\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_move(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    shutil.move(csv_file, 'test_processed');\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform(df):\n",
    "    df['hash'] = pd.Series((hash(tuple(row)) for _, row in df.iterrows()))\n",
    "    df_nodupe = df[~df.duplicated()]\n",
    "    \n",
    "    return df_nodupe\n",
    "    \n",
    "\n",
    "def insert(df):\n",
    "    df.to_json('ETL_json_file', orient='index')\n",
    "    \n",
    "    client = MongoClient()\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    \n",
    "    db = client['etl_db']\n",
    "    # Create database named 'etl_db'\n",
    "\n",
    "    # Drop collection if it already exist\n",
    "    #db.etl_data.drop() # Drop collection if it already exist\n",
    "\n",
    "    collection = db['schedule_etl_data']\n",
    "    # Create collection called 'schedule_etl_data'\n",
    "    \n",
    "    with open('ETL_json_file') as f:\n",
    "        file_data = json.load(f)\n",
    "        collection.insert_one(file_data) \n",
    "        client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n",
      "Performing an ETL process...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#Source Code\n",
    "#https://github.com/dbader/schedule\n",
    "\n",
    "def job():\n",
    "    print(\"Performing an ETL process...\")\n",
    "    csv_files = glob.glob('test_input' + '\\*.csv')\n",
    "    dfs = [read_and_move(csv_file) for csv_file in csv_files]\n",
    "    transformed_dfs = [transform(df) for df in dfs]\n",
    "    for df in transformed_dfs:\n",
    "        insert(df)\n",
    "    print(\"DONE\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "schedule.every(1).minutes.do(job)\n",
    "\n",
    "while 1:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
